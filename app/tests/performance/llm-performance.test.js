#!/usr/bin/env bun

// Detailed delay analysis to find where slowness occurs
import { QiAgentFactory, ConfigLoader } from './lib/dist/index.js';

async function analyzeDelays() {
  try {
    console.log('üîß Starting delay analysis...');
    const overallStart = Date.now();
    
    // Step 1: Configuration loading
    const configStart = Date.now();
    const configLoader = new ConfigLoader('./config/qi-config.yaml');
    const config = configLoader.loadConfig();
    console.log(`‚úÖ Config loaded in ${Date.now() - configStart}ms`);

    // Step 2: Agent initialization
    const initStart = Date.now();
    const agentFactory = new QiAgentFactory(config);
    await agentFactory.initialize();
    console.log(`‚úÖ Agent initialized in ${Date.now() - initStart}ms`);

    // Step 3: First message processing
    console.log('üí¨ Testing first message (may include model loading)...');
    const firstMsgStart = Date.now();
    
    let firstTokenReceived = false;
    let tokenCount = 0;
    
    await agentFactory.stream(
      [{ role: 'user', content: 'Say hello' }],
      {
        onToken: (token) => {
          tokenCount++;
          if (!firstTokenReceived) {
            firstTokenReceived = true;
            const firstTokenTime = Date.now() - firstMsgStart;
            console.log(`üöÄ FIRST TOKEN after ${firstTokenTime}ms`);
            
            if (firstTokenTime > 1000) {
              console.log('‚ö†Ô∏è  SLOW: First token took over 1 second');
            } else if (firstTokenTime > 500) {
              console.log('‚ö†Ô∏è  MODERATE: First token took over 500ms');
            } else {
              console.log('‚úÖ FAST: First token under 500ms');
            }
          }
        },
        onComplete: (response) => {
          const totalFirstMsg = Date.now() - firstMsgStart;
          console.log(`‚úÖ First message completed in ${totalFirstMsg}ms (${tokenCount} tokens)`);
          
          // Step 4: Second message (should be faster)
          console.log('üí¨ Testing second message (model should be warm)...');
          const secondMsgStart = Date.now();
          
          agentFactory.stream(
            [
              { role: 'user', content: 'Say hello' },
              { role: 'assistant', content: response },
              { role: 'user', content: 'Say goodbye' }
            ],
            {
              onToken: (token) => {
                const secondFirstToken = Date.now() - secondMsgStart;
                console.log(`üî• SECOND MESSAGE first token after ${secondFirstToken}ms`);
                
                if (secondFirstToken > 200) {
                  console.log('‚ùå ISSUE: Second message still slow - not model loading');
                } else {
                  console.log('‚úÖ GOOD: Second message fast - was model loading delay');
                }
                
                const overallTime = Date.now() - overallStart;
                console.log(`üìä ANALYSIS COMPLETE in ${overallTime}ms total`);
                process.exit(0);
              },
              onComplete: () => process.exit(0),
              onError: (error) => {
                console.error('‚ùå Second message error:', error);
                process.exit(1);
              }
            }
          );
        },
        onError: (error) => {
          console.error('‚ùå First message error:', error);
          process.exit(1);
        }
      }
    );

  } catch (error) {
    console.error('‚ùå Analysis failed:', error);
    process.exit(1);
  }
}

analyzeDelays();